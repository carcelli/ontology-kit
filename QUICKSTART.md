# Quick Start Guide: Hyperdimensional Agent Kit

## Goal
Build Phase 1 foundation in 2 weeks: vector space + ontology + basic scaffolding.

---

## Bootstrap (5 minutes)

```bash
# 1. Create directory structure
mkdir -p src/agent_kit/{vectorspace,ontology,agents,optimization,tools}
mkdir -p tests/{unit,integration}
mkdir -p assets/ontologies
mkdir -p examples
mkdir -p scripts

# 2. Create __init__ files
touch src/agent_kit/__init__.py
touch src/agent_kit/vectorspace/__init__.py
touch src/agent_kit/ontology/__init__.py
touch src/agent_kit/agents/__init__.py
touch src/agent_kit/optimization/__init__.py
touch src/agent_kit/tools/__init__.py

# 3. Install dependencies
python -m pip install --upgrade pip
python -m pip install -e .[dev]

# 4. Run initial tests
pytest tests/ -v
```

---

## Phase 1 Checklist (Weeks 1-2)

### Week 1: Vector Space Foundation
- [ ] **Day 1-2**: `src/agent_kit/vectorspace/embedder.py`
  - Wrapper around SentenceTransformer
  - Batch embedding with progress bar
  - Save/load model from cache
  - Test: embed 100 sentences, check shape (N, 384)

- [ ] **Day 3-4**: `src/agent_kit/vectorspace/index.py`
  - FAISS IndexFlatIP initialization
  - Add vectors with metadata (IDs)
  - Query top-k with distance scores
  - Save/load index from disk
  - Test: insert 1000 vectors, query 10, verify recall@10

- [ ] **Day 5**: `src/agent_kit/vectorspace/geometry.py`
  - Cosine similarity function
  - Euclidean distance
  - Pairwise distance matrix
  - Test: verify triangle inequality, symmetry

### Week 2: Ontology Foundation
- [ ] **Day 1-2**: `assets/ontologies/core.ttl`
  - Define 5 classes: Agent, Task, Tool, State, Action
  - Define 10 relations: hasPrerequisite, requiresTool, navigatesTo, etc.
  - Add example instances (2-3 per class)
  - Validate with `rapper` or online TTL validator

- [ ] **Day 3-4**: `src/agent_kit/ontology/loader.py`
  - Parse TTL with rdflib
  - Load into in-memory graph
  - SPARQL query wrapper
  - Test: load core.ttl, query all classes, verify count

- [ ] **Day 5**: `src/agent_kit/ontology/schema.py`
  - Python dataclasses for Agent, Task, Tool, State, Action
  - FromRDF deserializer (SPARQL → dataclass)
  - ToRDF serializer (dataclass → triples)
  - Test: roundtrip serialize/deserialize

---

## Development Workflow

```bash
# Before every commit
make lint      # or: ruff check src tests && black src tests
make test      # or: pytest tests/ --cov=agent_kit
make typecheck # or: mypy src

# Run integration tests (slow)
pytest tests/integration -m slow

# Profile a script
python -m cProfile -o profile.stats scripts/benchmark_embedder.py
python -m pstats profile.stats
```

---

## Reproducibility Checklist

1. **Snapshot ontology + data**: Commit `assets/ontologies/core.ttl` alongside any dataset under `data/<version>/` and tag both with the same semantic version.
2. **Pin seeds + configs**: Export `MODEL_NAME`, `EMBED_DIM`, and `PYTHONHASHSEED=0` inside `.env` so hyperdimensional embeddings can be regenerated byte-for-byte.
3. **Record artifact lineage**: Every run of `python scripts/refresh_embeddings.py` should output to `artifacts/hyperdimensional/<version>/` and log the git SHA + ontology checksum.
4. **Validate navigation**: Run `pytest tests/integration -m hyperdim` (add the marker when writing tests) to ensure agents still traverse the ontology-guided vector space deterministically.
5. **Automate in CI**: Wire the above commands into GitHub Actions so pull requests cannot merge unless embeddings + ontology snapshots remain in sync.

Following this loop guarantees that contributors can rebuild the ontology-informed hyperdimensional space and reproduce agent navigation results on any machine.

---

## Key Files to Create (Priority Order)

1. ✅ `ARCHITECTURE_PLAN.md` (done)
2. ⬜ `pyproject.toml` — deps + build config
3. ⬜ `Makefile` — lint, test, typecheck shortcuts
4. ⬜ `src/agent_kit/vectorspace/embedder.py`
5. ⬜ `src/agent_kit/vectorspace/index.py`
6. ⬜ `assets/ontologies/core.ttl`
7. ⬜ `src/agent_kit/ontology/loader.py`
8. ⬜ `tests/unit/test_embedder.py`
9. ⬜ `tests/unit/test_ontology_loader.py`
10. ⬜ `examples/01_embed_and_search.py` — demo script

---

## Success Criteria (Phase 1)

Run this to verify Phase 1 completion:
```python
# examples/phase1_validation.py
from agent_kit.vectorspace import Embedder, VectorIndex
from agent_kit.ontology import OntologyLoader

# 1. Embed 1000 sentences
embedder = Embedder(model_name='all-MiniLM-L6-v2')
texts = [f"Task {i}: do something" for i in range(1000)]
embeddings = embedder.embed_batch(texts)
assert embeddings.shape == (1000, 384)

# 2. Build index and query
index = VectorIndex(dim=384)
index.add(embeddings, ids=list(range(1000)))
results = index.query(embeddings[0], k=10)
assert len(results) == 10
assert results[0]['id'] == 0  # self should be top result

# 3. Load ontology
loader = OntologyLoader('assets/ontologies/core.ttl')
graph = loader.load()
classes = list(graph.subjects(rdf.type, owl.Class))
assert len(classes) >= 5  # Agent, Task, Tool, State, Action

print("✅ Phase 1 validation passed!")
```

---

## Debugging Tips

**Embedding shape mismatch?**
- Check model name: `all-MiniLM-L6-v2` → 384D, `all-mpnet-base-v2` → 768D
- Verify batch size doesn't exceed memory

**FAISS index slow?**
- Use GPU version: `faiss-gpu` instead of `faiss-cpu`
- Switch to IndexIVFFlat for >1M vectors

**Ontology won't parse?**
- Validate TTL syntax: `rapper -i turtle -o ntriples core.ttl`
- Check prefixes are declared

**Tests fail intermittently?**
- Seed random state: `np.random.seed(42)`
- Mock external APIs (OpenAI, etc.)

---

## What's Next?

After Phase 1 ✅:
1. **Phase 2**: Implement Agent loop (observe/plan/act/reflect)
2. **Phase 3**: Add contrastive fine-tuning for embeddings
3. **Phase 4**: Introduce RL policy (PPO)
4. **Phase 5**: Meta-optimization + auto-tuning

Track progress in GitHub Issues or JIRA; tag with `phase-1`, `phase-2`, etc.

---

**Questions?** Check `ARCHITECTURE_PLAN.md` Section 4 for detailed deliverables per phase.
